{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "from stanfordnlp.utils.resources import DEFAULT_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"達沃斯世界經濟論壇是每年全球政商界領袖聚在一起的年度盛事。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pipeline\n",
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd_tokenizer.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd_tagger.pt', 'pretrain_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd.pretrain.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd_lemmatizer.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd_parser.pt', 'pretrain_path': '/home/johnny/stanfordnlp_resources/zh_gsd_models/zh_gsd.pretrain.pt', 'lang': 'zh', 'shorthand': 'zh_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"Building pipeline\")\n",
    "pipeline = stanfordnlp.Pipeline(models_dir=DEFAULT_MODEL_DIR, lang='zh', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pipeline(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence : 達沃斯世界經濟論壇是每年全球政商界領袖聚在一起的年度盛事。\n",
      "The tokenizer split the input into 29 sentences.\n",
      "The token of the test sentence : \n",
      "<Token index=1;words=[<Word index=1;text=達沃斯;lemma=達沃斯;upos=PROPN;xpos=NNP;feats=_;governor=4;dependency_relation=nmod>]>\n",
      "<Token index=2;words=[<Word index=2;text=世界;lemma=世界;upos=NOUN;xpos=NN;feats=_;governor=4;dependency_relation=nmod>]>\n",
      "<Token index=3;words=[<Word index=3;text=經濟;lemma=經濟;upos=NOUN;xpos=NN;feats=_;governor=4;dependency_relation=nmod>]>\n",
      "<Token index=4;words=[<Word index=4;text=論壇;lemma=論壇;upos=NOUN;xpos=NN;feats=_;governor=16;dependency_relation=nsubj>]>\n",
      "<Token index=5;words=[<Word index=5;text=是;lemma=是;upos=AUX;xpos=VC;feats=_;governor=16;dependency_relation=cop>]>\n",
      "<Token index=6;words=[<Word index=6;text=每年;lemma=每年;upos=DET;xpos=DT;feats=_;governor=10;dependency_relation=nmod>]>\n",
      "<Token index=7;words=[<Word index=7;text=全球;lemma=全球;upos=NOUN;xpos=NN;feats=_;governor=10;dependency_relation=nmod>]>\n",
      "<Token index=8;words=[<Word index=8;text=政;lemma=政;upos=PART;xpos=PFA;feats=_;governor=9;dependency_relation=case:pref>]>\n",
      "<Token index=9;words=[<Word index=9;text=商界;lemma=商界;upos=NOUN;xpos=NN;feats=_;governor=10;dependency_relation=nmod>]>\n",
      "<Token index=10;words=[<Word index=10;text=領袖;lemma=領袖;upos=NOUN;xpos=NN;feats=_;governor=11;dependency_relation=nsubj>]>\n",
      "<Token index=11;words=[<Word index=11;text=聚;lemma=聚;upos=VERB;xpos=VV;feats=_;governor=16;dependency_relation=acl:relcl>]>\n",
      "<Token index=12;words=[<Word index=12;text=在;lemma=在;upos=VERB;xpos=VV;feats=_;governor=11;dependency_relation=mark>]>\n",
      "<Token index=13;words=[<Word index=13;text=一起;lemma=一起;upos=NOUN;xpos=NN;feats=_;governor=11;dependency_relation=obj>]>\n",
      "<Token index=14;words=[<Word index=14;text=的;lemma=的;upos=PART;xpos=DEC;feats=_;governor=11;dependency_relation=mark:relcl>]>\n",
      "<Token index=15;words=[<Word index=15;text=年度;lemma=年度;upos=NOUN;xpos=NN;feats=_;governor=16;dependency_relation=nmod>]>\n",
      "<Token index=16;words=[<Word index=16;text=盛事;lemma=盛事;upos=NOUN;xpos=NN;feats=_;governor=0;dependency_relation=root>]>\n",
      "<Token index=17;words=[<Word index=17;text=。;lemma=。;upos=PUNCT;xpos=.;feats=_;governor=16;dependency_relation=punct>]>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input sentence : {}\".format(test_sentence))\n",
    "print(\"The tokenizer split the input into {} sentences.\".format(len(test_sentence)))\n",
    "print(\"The token of the test sentence : \")\n",
    "doc.sentences[0].print_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_mldb",
   "language": "python",
   "name": "python_mldb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
